# 数据

## 数据三剑客

### numpy

### pandas

#### Series

- 创建
  - 列表：s1 = Series([1,2,3,4,5,6],index=list('abcdef'))
  - 字典：s2 = Series({"a":1,"b":2,"c":3})
  - 索引：如果不给index，默认从0开始到n-1
- 注意：通过ndarray创建series是相互关联的，series改变后ndarray也会改变，列表不是相互关联的



- 索引和切片
  - 显示索引(切片时全闭区间)
    - s1.loc['a']、s1.loc['a':'d']
    - s1['a']、s1['a':'d']
  - 隐式索引（切片时全闭区间）
    - s1.iloc[0]、s1.iloc[0:5]
- 属性
  - values
  - index
  - shape
- 方法
  - head（）：查看前五个
  - tail（）：查看后五个



- series有空数据也可以直接进行运算



- 对空数据进行筛选和处理
  - isnull（）
    - 筛选空数据：
      - cond = s3.isnull()
        s3[cond]
  - notnull（）
    - 筛选非空数据
    - cond = s3.notnull()
      s3[cond]
- 运算
  - 索引必须相同，不相同会产生空数据，相加不想产生空数据的话使用
  - s1.add(s2,fill_value=0):索引没有对齐的时候用0填充
  - python运算符+、-会产生空数据

#### DataFrame

##### 创建

```
创建：
	通过ndarray创建：
	d1 = DataFrame(np.random.randint(0,100,size=				(5,3)),index=list('abcde'),columns=["python","en","math"])
	通过字典创建：
		d2 = DataFrame({"python":[100,200,300],"en":				[400,500,600],"math":[700,800,900]},index=list("abc"))
		
```

##### 属性

```
属性：
	values、index、columns、shape
```

##### 索引

```
索引：
	列索引：
		d2['python']     ---》  得到series数据
		d2[['python']]   ---》  得到DataFrame数据
		列是属性，所以可以通过点来获取
		d2.python    -----》   得到series数据
	行索引：
		d2.loc['a'] --》 返回series数据
		d2.loc[['a','b']] ---》 返回DataFrame数据
		
		d2.iloc[0] --》 返回series数据
		d2.iloc[[0,1]] ---》 返回DataFrame数据
		
	数据series获取：
		s4 = 											       							Series([True,False,True,False,True,False,True,False,True,False],index=d4.index)

	
		
对元素进行解锁：
	d2['python']['a'] --->返回元素的值
	d2.loc['a']['python'] ----> 返回元素的值 注意：对用此方式获取的元素进行赋值，原来数据不会改变，而是新生成了一个数据
	d2.loc['a','python'] ----> 返回元素的值
			
```

##### 切片

```
切片：
	行切片：
		d2["a":"c"]
		d2.loc["a":"c"]
		d2.iloc[0:3]
		这三种方式都是针对行切片
		
	列切片：
		只有一种方式：
		d2.iloc[:,0:2]：逗号是二维思想
		
	
```

##### 运算

```bush
运算：
	DataFarme与DataFarme运算：
	
	python运算符对不齐产生空值
	用d1.add(d2)等等
	
	下面是Python 操作符与pandas操作函数的对应表：

| Python Operator | Pandas Method(s)                      |
|-----------------|---------------------------------------|
| ``+``           | ``add()``                             |
| ``-``           | ``sub()``, ``subtract()``             |
| ``*``           | ``mul()``, ``multiply()``             
| ``/``         | ``truediv()``, ``div()``, ``divide()``|
| ``//``          | ``floordiv()``                        |
| ``%``           | ``mod()``                             |
| ``**``          | ``pow()``                             |

	dataframe和series的运算
	df2是dataframe数据类型，s1是series数据类型
    df2.add(s1,axis=0)或者df2.add(s1,axis='index')
    df2.add(s1,axis=1)或者df2.add(s1,axis='columns')
	
		
```

##### 数据清洗

```
对空数据的操作：
条件筛选：
	isnull()
	notnull()
	any()
	all()
	轴：axis = 0/1，axis指向谁就运算谁，谁就消失
	d4.isnull().all(axis=1)
	

空数据删除：
d1.dropna(how='all'):删除全部为空的行
d1.dropna(how='any'):只要某一行有空数据就全部删除


空数据填充：
空数据全部填充为某个值：d1.fillna(value=1)
数据向前填充：d4.fillna(method='pad')
数据向后填充：d4.fillna(method='backfill')
填充数据平均值：d4.fillna(d4.mean())
填充数据中位数：d4.fillna(d4.media())

让浮点型数据按格式输出：
pd.set_option('display.float_format',lambda x:'%0.2f'% x)

总结：
如果数据量非常大，那么可以直接dropna删除空数据，如果数据量不够大则可以填充数据
```

##### 多层索引

```
Series的多层索引：
s = Series(np.random.randint(0,150,size = 6),index = pd.MultiIndex.from_product([['a','b','c'],['期中','期末']]))

DataFrame的多层索引：
通过列表构建：
df = DataFrame(np.random.randint(0,150,size = (6,3)),columns=['Python','En','数学'],
               index = pd.MultiIndex.from_arrays([['a','a','b','b','c','c'],['期中','期末','期中','期末','期中','期末']]))


通过tuple构建：
df = DataFrame(np.random.randint(0,150,size = (6,3)),columns=['Python','En','数学'],
               index = pd.MultiIndex.from_tuples([('a','期中'),('a','期末'),('b','期中'),('b','期末'),('c','期中'),('c','期末')]))


通过product构建：
df2 = DataFrame(np.random.randint(0,150,size = (3,6)),
                columns=pd.MultiIndex.from_product([['Python','En','数学'],['期中','期末']]),
                index = list('abc'))

此处省略，看课件

```

##### 级联操作

```
np.concatenate:

nd1 = np.random.randint(0,100,size=(5,3))
nd2 = np.random.randint(0,100,size=(5,3))
display(nd1,nd2)
np.concatenate((nd1,nd2),axis=1)


pd.concat:
pd.concat((d1,d2),axis=1)
axis=1纵向增多
axis=0横向增多

参数keys添加标记：如添加其中、期末配合stack（）和unstack（）的使用

忽略警告：
import warnings
warnings.filterwarnings('ignore')

参数join级联方式：
join='outer':外连接保存所有的数据
join=’inner‘：内连接保存索引相同的数据


参数join_axes=[df1.columns]:指定输出轴，指定谁的columns输出的时候就按照谁的columns格式输出


d1.append():只支持追加行

```

##### merge合并

```
与concate的区别：
concate：直接拼接在后边
merge：是根据相同列值相同进行合并


使用：
df1.merge(df2,how='inner',on='color',suffixes=('_早市','_夜市')，right_on='Python',left_on='python')

参数解释：
how：一般inner匹配就可以，还有outer：保留全部、left：保留左边所有属性、right：保留右边所有属性
on：指定某行相同进行匹配
suffixes：进行相同属性之间的区别
right_on和left_on成对出现：意思是进行合并参考的两行

如果根据行索引进行merge合并，则只需要这么写就好了：
left_index=True，right_index=True

合并以后会有重复的列怎么删除：
d1.drop(labels=['python'],axis=1)
参数说明：
labels中填写所要删除属性列，axis指定从行中找索引还是从列中找索引，axis=1是从列中找索引





```

## matplotlib

### Series和pandas中的绘图

#### 线形图

```
绘制单个线形图：
调用Series的plot方法
x = np.linspace(0,2*np.pi,100)
y = np.sin(x)
s = Series(y)
s.plot()

绘制多个线形图：
调用DataFrame的plot方法
df = DataFrame({'sin':y,'cos':np.cos(x)})
df.plot()


绘制密度曲线：
s.plot(kind='kde')

```

#### 柱状图

```
plot中的kind="bar"或者kin="barh"绘制柱状图，横向或纵向的
```

#### 直方图

```
统计出现次数：
使用hist（）函数进行绘制
s.hist(bins=1000)可以分成1000份
```

#### 图片均衡化

```
from skimage import data,exposure
moon = data.moon()

# 直方图均衡化
moon_hist = exposure.equalize_hist(moon)

plt.figure(figsize=(8,8))

axes = plt.subplot(2,2,1)
axes.imshow(moon,cmap = 'gray')

axes = plt.subplot(2,2,2)
axes.imshow(moon_hist,cmap = 'gray')

# 将原图的数据绘制成直方图
moon_data = moon.reshape(-1)

moon_hist_data = moon_hist.reshape(-1)

axes = plt.subplot(2,2,3)
_ = axes.hist(moon_data,bins = 256)

axes = plt.subplot(2,2,4)
_ = axes.hist(moon_hist_data,bins = 256)
```

#### 散布图

```
作用：
查看两个属性间的关系
df = DataFrame(np.random.randint(0,150,size = (100,2)),columns=['Python','En'])
df
# 这里只能查看两个属性之间的关系
df.plot(x = 'Python',y = 'En',kind = 'scatter')

散布图矩阵：
查看多个属性间的关系
_ = pd.plotting.scatter_matrix(df,figsize=(12,9),alpha = 1,grid = True,diagonal='kde')
说明：
diagonal='kde'
diagonal='hist'


```

### matplotlib中的绘图







## 算法

### KNN算法

```
用于分类：


1、将数据处理成二维数据
2、切分数据，分成训练数据和测试数据
3、训练数据归一化
4、训练数据均衡化
5、训练模型测试模型，对模型进行打分

介意：多次打分求平均

算法对数据的要求：
1、数据归一化
2、数据均衡
3、选取特征明显属性（放大特征0-1、2-3对数据特征放大）（两个属性进行相乘（象限的划分））
4、将非数值数据转化成数值数据

代码如下：
import numpy as np

import pandas as pd

from sklearn.neighbors import KNeighborsClassifier

from sklearn.model_selection import train_test_split

# 微观，得到
cancer = pd.read_csv('./cancer.csv',sep = '\t')
cancer

y = cancer['Diagnosis']
X = cancer.iloc[:,2:]

X.shape

X_train,X_test,y_train,y_test = train_test_split(X,y,test_size = 0.15)

# X_train中对应的目标值y_train(M,B)
# 但是对于KNN而言，数据量足够多，没有影响
y_train.value_counts()

knn = KNeighborsClassifier(n_neighbors=5)

knn.fit(X_train,y_train)

y_ = knn.predict(X_test)

(y_ == y_test).mean()


from imblearn.over_sampling import SMOTE

# 该方法，将数量比较少的一方，使用KNN近邻算法复制多份
smote = SMOTE()

X_train2,y_train2 = smote.fit_sample(X_train,y_train)

# 样本均衡的准去了
knn = KNeighborsClassifier()

knn.fit(X_train2,y_train2)

# 测试的数据样本不均衡，没有影响
y_ = knn.predict(X_test)

(y_ == y_test).mean()


样本归一化：
归一化公式:(样本-min)/(max-min)
第二种公式：（样本-平均值）/标准差


用于回归：
用于回归没有方程，是通过距离远近来计算的，没有斜率和截距
```

### 线性回归

